---
title: "Wine suggestion"
author: "Hye_Lim_Kim"
date: "10/2/2020"
output:
  html_document: default
  pdf_document: default
  word_document: default
---
```{r,include=FALSE}
library(dplyr)
library(ggplot2)
library(factoextra)
library(cluster)
library(useful)
```

## Introduction
#### Based on the wine information data, the purpose of this project is to cluster customers and suggest similar/new items to increase market profit and better convenience for customers. 
#### There are 2 different methods to suggest wine based on customers' purchase type preferences (similar/new).
#### 1. Customers will purchase similar products based on their last purchase. 
#### 2. Customers will take an adventure and purchase new items.
____________________________________________________________________________________________________ 


```{r,echo=FALSE}
# Understanding the data
df <- read.csv("wine.data.csv",header=TRUE)

# Input missing column names
colnames(df) <- c('Cultivar','Alcohol','Malic acid','Ash','Alcalinity of ash','Magnesium','Total phenols','Flavanoids','Nonflavanoid phenols','Proanthocyanins','Color intensity','Hue','OD280/Od315 of diluted wines','Proline')
# Check missing values
# colSums(is.na(df))
df <- df[,-1] # Delete Cultivar (Not necessary)
```

```{r,echo=FALSE}
# Normalization
norm_df <- scale(df)
```

### 1. To recommend similar products use 'Euclidean Distance'
```{r}
# Clustering - Euclidean Distance
df.dist <- dist(norm_df,method="euclidean") %>% as.matrix()
el_recommend <- df.dist %>% sort(1,decreasing = F)

```
* The number shows similarity to the comparison target. You can suggest wine in order within the category with number 0.
 
### 2. To recommend different type of wine 
#### __i) Clustering - Kmeans__


```{r,echo=FALSE}
# Clustering - Kmeans
set.seed(1234)
fviz_nbclust(norm_df,kmeans,method="wss",k.max=15) + theme_minimal() + ggtitle("Elbow method")
## k = 3
fviz_nbclust(norm_df, kmeans, method="silhouette", k.max=15) + theme_minimal() + ggtitle("Silhouette method")
## k = 3

df_kmeans <- kmeans(norm_df, centers=3, iter.max=1000)
```


* Based on both 'Elbow method' and 'Silhouette method', it is best to cluster into 3 groups. 

```{r,echo=FALSE}
# Visualization
plot(df_kmeans,norm_df)

# Add to original dataset
df$kmeans_cluster <- df_kmeans$cluster
```

#### __ii) Clustering - k medoids__
``` {r, echo=FALSE}
# Clustering - k medoids
set.seed(123)
fviz_nbclust(norm_df,cluster::pam,method="wss",k.max = 15)+theme_minimal()+ggtitle("Elbow plot")
## k=3
fviz_nbclust(norm_df,cluster::pam,method="silhouette",k.max=15)+theme_minimal()+ggtitle("Silhouette plot")
## k=3

# Visualization
df_kmedoids <- cluster::pam(norm_df,k=3)
plot(df_kmedoids)

# Add to original dataset
df$kmedoid_cluster <- df_kmedoids$cluster  
```


* Based on both 'Elbow method' and 'Silhouette method', it is best to cluster into 3 groups. 

#### __iii) Clustering - Hierarchial clustering__
```{r,echo=FALSE}
# Clustering - Hierarchial clustering
set.seed(12)
fviz_nbclust(norm_df,hcut, method="wss",k.max=15)+theme_minimal()+ggtitle("Elbow plot")
fviz_nbclust(norm_df,hcut,method="silhouette",k.max=15)+theme_minimal()+ggtitle("Silhouette plot")
## k=3

# Visualization
df_hclust_single <- hclust(dist(norm_df),method="single")
df_hclust_cplt <- hclust(dist(norm_df),method='complete')
df_hclust_avg <- hclust(dist(norm_df),method='average')
df_hclust_ward <- hclust(dist(norm_df),method='ward.D')

par(mfrow=c(2,2))
plot(df_hclust_single,hang=-1,cex=0.4)
rect.hclust(df_hclust_single,k=3,border='skyblue')
plot(df_hclust_cplt,hang=-1,cex=0.4)
rect.hclust(df_hclust_cplt,k=3,border='skyblue')
plot(df_hclust_avg,hang=-1,cex=0.4)
rect.hclust(df_hclust_avg,k=3,border='skyblue')
plot(df_hclust_ward,hang=-1,cex=0.4)
rect.hclust(df_hclust_ward,k=3,border='skyblue')

# Add to original dataset
# 'complete' and 'ward' have clustered better
hclust_cluster <- cutree(df_hclust_ward,k=3)
df$hclust_cluster <- hclust_cluster
```

* In Hierarchial clustering method, 'complete' and 'ward.D' shows better result. 

## __Conclusion__
### 1) Use 'Euclidean Distance' to recommend similar wine.
### 2) Use either 'Kmeans' or 'Hierarchial clustering' to recommend different type of wine.
